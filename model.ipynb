{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from constants import *\n",
    "from GTZAN import GTZAN\n",
    "from visualization import *\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeatTracker(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size=128, num_layers=2):\n",
    "        super(BeatTracker, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "                        nb, \n",
    "                        hidden_size, \n",
    "                        num_layers, \n",
    "                        bidirectional=True, \n",
    "                        dropout=0.5,\n",
    "                        batch_first=True)\n",
    "        self.hid_to_beat = nn.Linear(2 * hidden_size, 2)\n",
    "        self.hidden = None\n",
    "        \n",
    "        self.loss_function = nn.NLLLoss()\n",
    "        \n",
    "        self.lr = 0.001\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def forward(self, spec):\n",
    "        x = self.lstm(spec)[0]\n",
    "        x = self.hid_to_beat(x)\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "    def set_lr(self, lr):\n",
    "        self.lr = lr\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = lr\n",
    "    \n",
    "    def loss(self, spec, onsets, isbeat):\n",
    "        output = self(spec)\n",
    "        output = output[onsets == 1]\n",
    "        target = isbeat[onsets == 1]\n",
    "        loss = self.loss_function(output, target)\n",
    "        return loss\n",
    "\n",
    "    def loss_from_dataset(self, dataset, batch_size=16):\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for specs, onsets, isbeat in dataloader:\n",
    "                loss += self.loss(spec, onsets, isbeat).item()\n",
    "            loss /= len(dataloader)\n",
    "        return loss\n",
    "    \n",
    "    def learn(self, spec, onsets, isbeat):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self(spec)\n",
    "        output = output[onsets == 1]\n",
    "        target = isbeat[onsets == 1]\n",
    "        loss = self.loss_function(output, target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        predic = torch.argmax(output, dim=1)\n",
    "        accuracy = torch.sum(predic == target).item() / predic.shape.numel()\n",
    "        \n",
    "        return loss.item(), accuracy\n",
    "    \n",
    "    def fit(self, dataset, batch_size=1, epochs=1):\n",
    "        loss_hist = np.zeros((epochs, -(-len(dataset) // batch_size)))\n",
    "        accu_hist = np.zeros((epochs, -(-len(dataset) // batch_size)))\n",
    "        for e in range(epochs):\n",
    "            start = time.time()\n",
    "            \n",
    "            dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            for i, (spec, onsets, isbeat) in enumerate(dataloader):\n",
    "                loss, accuracy = self.learn(spec, onsets, isbeat)\n",
    "                loss_hist[e, i] = loss\n",
    "                accu_hist[e, i] = accuracy\n",
    "            \n",
    "            end = time.time()\n",
    "            t = end - start\n",
    "            eta = str(datetime.timedelta(seconds=int(t * (epochs - e - 1))))\n",
    "            print(f'| Epoch: {e + 1:{len(str(epochs))}} | ', end='')\n",
    "            print(f'Loss: {np.mean(loss_hist[e]):7.4f} | ', end='')\n",
    "            print(f'Accuracy: {np.mean(accu_hist[e]):5.4f} | ', end='')\n",
    "            print(f'{t / len(dataloader):.2f} s/b | Eta: {eta} |')\n",
    "        return loss_hist, accu_hist\n",
    "    \n",
    "    def predict(self, specs, onsets):\n",
    "        \"\"\"So far only works if batch_size = 1\"\"\"\n",
    "        with torch.no_grad():\n",
    "            output = model(specs)\n",
    "            output = output[onsets == 1]\n",
    "            pred_t = torch.argmax(output, dim=1)\n",
    "            onsets_frames = np.argwhere(onsets.squeeze(0) == 1).squeeze(0)\n",
    "            beats_frames = onsets_frames[pred_t == 1]\n",
    "            pred = torch.zeros_like(onsets)\n",
    "            pred[:, beats_frames] = 1\n",
    "        return pred\n",
    "    \n",
    "    def evaluate(self, specs, onsets, isbeat):\n",
    "        with torch.no_grad():\n",
    "            output = model(specs)\n",
    "            output = output[onsets == 1]\n",
    "            target = isbeat[onsets == 1]\n",
    "            predic = torch.argmax(output, dim=1)\n",
    "            \n",
    "            tn = torch.sum((predic == 0) & (target == 0)).item()\n",
    "            fp = torch.sum((predic == 1) & (target == 0)).item()\n",
    "            fn = torch.sum((predic == 0) & (target == 1)).item()\n",
    "            tp = torch.sum((predic == 1) & (target == 1)).item()\n",
    "        return tn, fp, fn, tp\n",
    "    \n",
    "    def evaluate_from_dataset(self, dataset, batch_size=16):\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "        ttn = 0\n",
    "        tfp = 0\n",
    "        tfn = 0\n",
    "        ttp = 0\n",
    "        for specs, onsets, isbeat in dataloader:\n",
    "            tn, fp, fn, tp = self.evaluate(specs, onsets, isbeat)\n",
    "            ttn += tn\n",
    "            tfp += fp\n",
    "            tfn += fn\n",
    "            ttp += tp\n",
    "        return ttn, tfp, tfn, ttp\n",
    "    \n",
    "    def freeze(self):\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def unfreeze(self):\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "class ToTensor(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        spec_np, onsets_np, isbeat_np = sample\n",
    "        \n",
    "        # Normalize to [-1, 1]\n",
    "        spec_np = 2 * (spec_np - spec_np.min()) / (spec_np.max() - spec_np.min()) - 1\n",
    "        spec = torch.tensor(spec_np.T, dtype=torch.float, device=device)\n",
    "        \n",
    "        onsets = torch.zeros(spec.shape[0], dtype=torch.long, device=device)\n",
    "        isbeat = torch.zeros(spec.shape[0], dtype=torch.long, device=device)\n",
    "        \n",
    "        onsets[onsets_np] = 1\n",
    "        isbeat[onsets_np[isbeat_np == 1]] = 1\n",
    "        \n",
    "        return spec, onsets, isbeat\n",
    "\n",
    "totensor = ToTensor()\n",
    "    \n",
    "def beat_track(isbeat):\n",
    "    onset_envelope = isbeat.squeeze(0).numpy()\n",
    "    tempo, bt = librosa.beat.beat_track(\n",
    "                            sr=sr, \n",
    "                            onset_envelope=onset_envelope, \n",
    "                            hop_length=hl, \n",
    "                            tightness=800)\n",
    "    return bt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a subset of the GTZAN dataset preprocessed using `preprocess-GTZAN` and split it into a train set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GTZAN(937, 'country', 20, getbeats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec, onsets, isbeat, beats = dataset[np.random.randint(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showspec(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showdata(spec, onsets, isbeat, beats, duration=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BeatTracker()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GTZAN(style='disco', idxs=20, transform=totensor)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "n_mb = len(dataloader) # number of minibatches\n",
    "lr = (10. ** -np.arange(0, 10, 10 / n_mb))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.zeros(n_mb)\n",
    "for i, (specs, onsets, isbeat) in enumerate(dataloader):\n",
    "    print(f'{i + 1}/{n_mb}')\n",
    "    model.set_lr(lr[i])\n",
    "    loss, accuracy = model.learn(specs, onsets, isbeat)\n",
    "    losses[i] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(lr, losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------------------------------------------\n",
      "| lstm.weight_ih_l0            | [512, 229]   |    117,248 |\n",
      "| lstm.weight_hh_l0            | [512, 128]   |     65,536 |\n",
      "| lstm.bias_ih_l0              | [512]        |        512 |\n",
      "| lstm.bias_hh_l0              | [512]        |        512 |\n",
      "| lstm.weight_ih_l0_reverse    | [512, 229]   |    117,248 |\n",
      "| lstm.weight_hh_l0_reverse    | [512, 128]   |     65,536 |\n",
      "| lstm.bias_ih_l0_reverse      | [512]        |        512 |\n",
      "| lstm.bias_hh_l0_reverse      | [512]        |        512 |\n",
      "| lstm.weight_ih_l1            | [512, 256]   |    131,072 |\n",
      "| lstm.weight_hh_l1            | [512, 128]   |     65,536 |\n",
      "| lstm.bias_ih_l1              | [512]        |        512 |\n",
      "| lstm.bias_hh_l1              | [512]        |        512 |\n",
      "| lstm.weight_ih_l1_reverse    | [512, 256]   |    131,072 |\n",
      "| lstm.weight_hh_l1_reverse    | [512, 128]   |     65,536 |\n",
      "| lstm.bias_ih_l1_reverse      | [512]        |        512 |\n",
      "| lstm.bias_hh_l1_reverse      | [512]        |        512 |\n",
      "| hid_to_beat.weight           | [2, 256]     |        512 |\n",
      "| hid_to_beat.bias             | [2]          |          2 |\n",
      " ----------------------------------------------------------\n",
      "\n",
      "Total number of parameters: 763,394\n"
     ]
    }
   ],
   "source": [
    "model = BeatTracker()\n",
    "model.to(device)\n",
    "print_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 16\n",
      "Valid size: 4\n"
     ]
    }
   ],
   "source": [
    "dataset = GTZAN(style='disco', idxs=20, transform=totensor)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "trainset, validset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "print(f'Train size: {train_size}')\n",
    "print(f'Valid size: {valid_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------\n",
      "| tp: 192 | fp: 245 |\n",
      "| fn:  14 | tn:  24 |\n",
      " -------------------\n",
      "Precision: 0.4394\n",
      "   Recall: 0.9320\n",
      " Accuracy: 0.4547\n"
     ]
    }
   ],
   "source": [
    "confusion(*model.evaluate_from_dataset(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---------------------\n",
      "| tp:  840 | fp: 1106 |\n",
      "| fn:   78 | tn:  105 |\n",
      " ---------------------\n",
      "Precision: 0.4317\n",
      "   Recall: 0.9150\n",
      " Accuracy: 0.4439\n"
     ]
    }
   ],
   "source": [
    "confusion(*model.evaluate_from_dataset(trainset, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_hist, accu_hist = model.fit(trainset, batch_size=3, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(lost_hist, axis=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion(*model.evaluate_from_dataset(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion(*model.evaluate_from_dataset(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), './data/model_02.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GTZAN import *\n",
    "from IPython.display import Audio\n",
    "\n",
    "def unibatch(spec_np, onsets_np, isbeat_np):\n",
    "    \"\"\" Get a minibatch of one sample from the original numpy data.\"\"\"\n",
    "    spec, onsets, isbeat = totensor((spec_np, onsets_np, isbeat_np))\n",
    "    spec = spec.unsqueeze(0)\n",
    "    onsets = onsets.unsqueeze(0)\n",
    "    isbeat = isbeat.unsqueeze(0)\n",
    "    return spec, onsets, isbeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained model and freeze its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BeatTracker()\n",
    "model.load_state_dict(torch.load('./data/model_02.pt', map_location=device))\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a random example from the GTZAN dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.random.choice(styles)\n",
    "n = np.random.randint(20)\n",
    "print(filename(s, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the beat track from the RNN algorithm and compare with librosa and ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN\n",
    "spec_np, onsets_np, isbeat_np, beats_np = loadGTZAN(s, n, True)\n",
    "spec, onsets, isbeat = unibatch(spec_np, onsets_np, isbeat_np)\n",
    "pred = model.predict(spec, onsets)\n",
    "bt = beat_track(pred)\n",
    "bt_times = librosa.frames_to_time(bt, sr, hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librosa\n",
    "onset_envelope = librosa.onset.onset_strength(S=spec_np)\n",
    "tempo, bt_lib = librosa.beat.beat_track(onset_envelope=onset_envelope)\n",
    "bt_lib_times = librosa.frames_to_time(bt_lib, sr, hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 2))\n",
    "plt.vlines(bt_lib_times, 2, 3, color='b', label='Librosa')\n",
    "plt.vlines(beats_np, 1, 2, color='g', label='Ground truth')\n",
    "plt.vlines(bt_times, 0, 1, color='r', label='RNN')\n",
    "plt.xlim(0, 30)\n",
    "plt.ylim(0, 3)\n",
    "plt.legend(frameon=True, framealpha=0.75, bbox_to_anchor=(1.15, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the three different beat tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = librosa.load(filename_audio(s, n), sr=sr)[0]\n",
    "Audio(wav, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN\n",
    "click = librosa.clicks(bt_times, length=len(wav), sr=sr)\n",
    "Audio(wav + click, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librosa\n",
    "click = librosa.clicks(bt_lib_times, length=len(wav), sr=sr)\n",
    "Audio(wav + click, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth (sort of)\n",
    "click = librosa.clicks(beats_np, length=len(wav), sr=sr)\n",
    "Audio(wav + click, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
